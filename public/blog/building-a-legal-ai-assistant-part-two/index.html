<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title> | Building your own LLM &amp; RAG with Python (# 2: Getting Answers)</title>
    
  
    <link rel="stylesheet" href="https://elvim.cc/style.css?h=501c6ea82db27d74ea03">
    
  <link rel="stylesheet" href="/css/custom.css">

    
        
    
</head>
<body>
    
<header class="space">
    <a href="https:&#x2F;&#x2F;elvim.cc&#x2F;">&LeftArrow; Home</a>
</header>

    
<main>
    <h1>Building your own LLM &amp; RAG with Python (# 2: Getting Answers)</h1>
    
    <p class="secondary small">
        21 August, 2025

        
        
        
        
        

        
        
        - Categories:
        
        
        <a href="https:&#x2F;&#x2F;elvim.cc&#x2F;categories&#x2F;llm&#x2F;">LLM</a>
        
        
    </p>
    
    <div class="space"></div>
    <h1 id="building-an-ai-assistant-with-python">Building an AI Assistant with Python</h1>
<h3 id="part-2-getting-answers">Part 2: Getting Answers</h3>
<p>In <a href="../part-1-tools-and-setup/">Part 1</a>, we:</p>
<ul>
<li>Installed Ollama to run a language model locally.</li>
<li>Installed Chroma to store and search text by meaning.</li>
<li>Split the Danish Housing Act into clean, overlapping <strong>chunks</strong> for easier retrieval.</li>
</ul>
<p>Now it‚Äôs time to put it all together and actually ask questions.</p>
<hr />
<h2 id="step-1-ingesting-the-law-into-chroma">Step 1: Ingesting the Law into Chroma</h2>
<p>To populate our vector database we will need some code that can ingest all the chunks of markdown we produced in the last post.
The ingestion script (<code>ingest.py</code>) loads all our prepared <code>.md</code> files and adds them into a Chroma collection.</p>
<p>Remember, that each chunk is stored with:</p>
<ul>
<li><strong>Text</strong> (the law paragraph or slice of it)</li>
<li><strong>Metadata</strong>: source file, paragraph number (¬ß), chapter, and chunk index</li>
</ul>
<p>This lets us later retrieve not only the text but also know <em>where it came from</em>.</p>
<p>An example of ingesting code could be like this:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#65737e;">#!/usr/bin/env python3
</span><span>
</span><span style="color:#b48ead;">import </span><span>os
</span><span style="color:#b48ead;">from </span><span>pathlib </span><span style="color:#b48ead;">import </span><span>Path
</span><span style="color:#b48ead;">import </span><span>chromadb
</span><span style="color:#b48ead;">from </span><span>chromadb.config </span><span style="color:#b48ead;">import </span><span>Settings
</span><span style="color:#b48ead;">from </span><span>chromadb.utils </span><span style="color:#b48ead;">import </span><span>embedding_functions
</span><span>
</span><span style="color:#bf616a;">DATA_DIR </span><span>= </span><span style="color:#bf616a;">Path</span><span>(&quot;</span><span style="color:#a3be8c;">data</span><span>&quot;)          </span><span style="color:#65737e;"># your pre-chunked files live here
</span><span style="color:#bf616a;">DB_DIR </span><span>= </span><span style="color:#bf616a;">Path</span><span>(&quot;</span><span style="color:#a3be8c;">db</span><span>&quot;)              </span><span style="color:#65737e;"># where Chroma stores data
</span><span style="color:#bf616a;">COLLECTION </span><span>= &quot;</span><span style="color:#a3be8c;">almenlejelov</span><span>&quot;      </span><span style="color:#65737e;"># change as you like
</span><span>
</span><span style="color:#65737e;"># Optional: quiet telemetry (I hate getting nonsense warnings in my terminal - tweak as you like)
</span><span>os.environ[&quot;</span><span style="color:#a3be8c;">CHROMADB_DISABLE_TELEMETRY</span><span>&quot;] = &quot;</span><span style="color:#a3be8c;">1</span><span>&quot;
</span><span>os.environ[&quot;</span><span style="color:#a3be8c;">CHROMA_TELEMETRY_ENABLED</span><span>&quot;] = &quot;</span><span style="color:#a3be8c;">false</span><span>&quot;
</span><span>os.environ[&quot;</span><span style="color:#a3be8c;">ANONYMIZED_TELEMETRY</span><span>&quot;] = &quot;</span><span style="color:#a3be8c;">false</span><span>&quot;
</span><span>
</span><span style="color:#65737e;"># A multilingual model that handles non-english languages
</span><span style="color:#bf616a;">EMB_MODEL </span><span>= &quot;</span><span style="color:#a3be8c;">paraphrase-multilingual-MiniLM-L12-v2</span><span>&quot;
</span><span>emb = embedding_functions.</span><span style="color:#bf616a;">SentenceTransformerEmbeddingFunction</span><span>(</span><span style="color:#bf616a;">model_name</span><span>=</span><span style="color:#bf616a;">EMB_MODEL</span><span>)
</span><span>
</span><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">main</span><span>():
</span><span>    </span><span style="color:#b48ead;">if </span><span>not DATA_DIR.</span><span style="color:#bf616a;">exists</span><span>():
</span><span>        </span><span style="color:#b48ead;">raise </span><span style="color:#bf616a;">SystemExit</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;</span><span style="color:#a3be8c;">Missing data directory: </span><span>{DATA_DIR.</span><span style="color:#bf616a;">resolve</span><span>()}&quot;)
</span><span>
</span><span>    </span><span style="color:#65737e;"># Spin up (persistent) Chroma client and collection
</span><span>    client = chromadb.</span><span style="color:#bf616a;">PersistentClient</span><span>(</span><span style="color:#bf616a;">path</span><span>=</span><span style="color:#bf616a;">str</span><span>(</span><span style="color:#bf616a;">DB_DIR</span><span>), </span><span style="color:#bf616a;">settings</span><span>=</span><span style="color:#bf616a;">Settings</span><span>(</span><span style="color:#bf616a;">anonymized_telemetry</span><span>=</span><span style="color:#d08770;">False</span><span>))
</span><span>    coll = client.</span><span style="color:#bf616a;">get_or_create_collection</span><span>(</span><span style="color:#bf616a;">name</span><span>=</span><span style="color:#bf616a;">COLLECTION</span><span>, </span><span style="color:#bf616a;">embedding_function</span><span>=emb, </span><span style="color:#bf616a;">metadata</span><span>={&quot;</span><span style="color:#a3be8c;">hnsw:space</span><span>&quot;: &quot;</span><span style="color:#a3be8c;">cosine</span><span>&quot;})
</span><span>
</span><span>    </span><span style="color:#65737e;"># Collect docs
</span><span>    docs, ids, metas = [], [], []
</span><span>    </span><span style="color:#b48ead;">for </span><span>i, p </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">enumerate</span><span>(</span><span style="color:#96b5b4;">sorted</span><span>(DATA_DIR.</span><span style="color:#bf616a;">rglob</span><span>(&quot;</span><span style="color:#a3be8c;">*.*</span><span>&quot;)), </span><span style="color:#bf616a;">start</span><span>=</span><span style="color:#d08770;">1</span><span>):
</span><span>        </span><span style="color:#b48ead;">if </span><span>p.suffix.</span><span style="color:#bf616a;">lower</span><span>() not in {&quot;</span><span style="color:#a3be8c;">.md</span><span>&quot;, &quot;</span><span style="color:#a3be8c;">.txt</span><span>&quot;} or not p.</span><span style="color:#bf616a;">is_file</span><span>():
</span><span>            </span><span style="color:#b48ead;">continue
</span><span>        text = p.</span><span style="color:#bf616a;">read_text</span><span>(</span><span style="color:#bf616a;">encoding</span><span>=&quot;</span><span style="color:#a3be8c;">utf-8</span><span>&quot;, </span><span style="color:#bf616a;">errors</span><span>=&quot;</span><span style="color:#a3be8c;">ignore</span><span>&quot;).</span><span style="color:#bf616a;">strip</span><span>()
</span><span>        </span><span style="color:#b48ead;">if </span><span>not text:
</span><span>            </span><span style="color:#b48ead;">continue
</span><span>
</span><span>        </span><span style="color:#65737e;"># Use a stable, readable id: relative path + index
</span><span>        rid = </span><span style="color:#b48ead;">f</span><span>&quot;{p.</span><span style="color:#bf616a;">relative_to</span><span>(</span><span style="color:#bf616a;">DATA_DIR</span><span>)}</span><span style="color:#a3be8c;">::</span><span>{i}&quot;
</span><span>        docs.</span><span style="color:#bf616a;">append</span><span>(text)
</span><span>        ids.</span><span style="color:#bf616a;">append</span><span>(rid)
</span><span>        metas.</span><span style="color:#bf616a;">append</span><span>({&quot;</span><span style="color:#a3be8c;">source</span><span>&quot;: </span><span style="color:#bf616a;">str</span><span>(p.</span><span style="color:#bf616a;">relative_to</span><span>(</span><span style="color:#bf616a;">DATA_DIR</span><span>))})
</span><span>
</span><span>    </span><span style="color:#b48ead;">if </span><span>not docs:
</span><span>        </span><span style="color:#b48ead;">raise </span><span style="color:#bf616a;">SystemExit</span><span>(&quot;</span><span style="color:#a3be8c;">No .md/.txt files found under ./data</span><span>&quot;)
</span><span>
</span><span>    </span><span style="color:#65737e;"># Write to Chroma
</span><span>    coll.</span><span style="color:#bf616a;">add</span><span>(</span><span style="color:#bf616a;">ids</span><span>=ids, </span><span style="color:#bf616a;">documents</span><span>=docs, </span><span style="color:#bf616a;">metadatas</span><span>=metas)
</span><span>    </span><span style="color:#96b5b4;">print</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;</span><span style="color:#a3be8c;">‚úÖ Ingested </span><span>{</span><span style="color:#96b5b4;">len</span><span>(docs)}</span><span style="color:#a3be8c;"> chunks into &#39;</span><span>{</span><span style="color:#bf616a;">COLLECTION</span><span>}</span><span style="color:#a3be8c;">&#39; at &#39;</span><span>{</span><span style="color:#bf616a;">DB_DIR</span><span>}</span><span style="color:#a3be8c;">/&#39;</span><span>&quot;)
</span><span>    </span><span style="color:#96b5b4;">print</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;</span><span style="color:#a3be8c;">   Embeddings: </span><span>{</span><span style="color:#bf616a;">EMB_MODEL</span><span>}&quot;)
</span><span>
</span><span style="color:#b48ead;">if </span><span>__name__ == &quot;</span><span style="color:#a3be8c;">__main__</span><span>&quot;:
</span><span>    </span><span style="color:#bf616a;">main</span><span>()
</span><span>
</span></code></pre>
<p>Now, when we run our script, we should hopefully see something like:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>$ python ingest.py
</span><span>‚úÖ Ingested 147 chunks into almenlejelov at db/
</span><span>
</span></code></pre>
<hr />
<h2 id="step-2-asking-a-question">Step 2: Asking a Question</h2>
<p>We have now populated our vector database and need to be able to interact with it. This is there the LLM comes into play.
let's make a script for asking questions - <code>ask.py</code>. The idea is:</p>
<ol>
<li>You type a question.</li>
<li>It converts your question into an <em>embedding</em> (vector).</li>
<li>Chroma finds the closest text chunks.</li>
<li>We build a prompt like:</li>
</ol>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>
</span><span>Here are relevant law texts:
</span><span>
</span><span>¬ß85: \[chunk text...]
</span><span>¬ß86a: \[chunk text...]
</span><span>
</span><span>Answer the question using only these.
</span><span>
</span></code></pre>
<ol start="5">
<li>This is sent to <strong>Ollama</strong>, which generates a natural-language answer.</li>
<li>The script shows both the <strong>answer</strong> and the <strong>cited sources</strong>.</li>
</ol>
<p>An example script for asking could be like this:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#65737e;">#!/usr/bin/env python3
</span><span style="color:#65737e;"># -*- coding: utf-8 -*-
</span><span>
</span><span style="color:#b48ead;">import </span><span>os
</span><span style="color:#b48ead;">import </span><span>sys
</span><span style="color:#b48ead;">import </span><span>chromadb
</span><span style="color:#b48ead;">from </span><span>chromadb.config </span><span style="color:#b48ead;">import </span><span>Settings
</span><span style="color:#b48ead;">from </span><span>chromadb.utils </span><span style="color:#b48ead;">import </span><span>embedding_functions
</span><span>
</span><span style="color:#bf616a;">DB_DIR </span><span>= &quot;</span><span style="color:#a3be8c;">db</span><span>&quot;                   </span><span style="color:#65737e;"># same dir as used during ingest
</span><span style="color:#bf616a;">COLLECTION </span><span>= &quot;</span><span style="color:#a3be8c;">almenlejelov</span><span>&quot;     </span><span style="color:#65737e;"># must match the ingest script
</span><span>
</span><span style="color:#65737e;"># turn off telemetry for clarity (Like in the ingest.py code)
</span><span>os.environ[&quot;</span><span style="color:#a3be8c;">CHROMADB_DISABLE_TELEMETRY</span><span>&quot;] = &quot;</span><span style="color:#a3be8c;">1</span><span>&quot;
</span><span>os.environ[&quot;</span><span style="color:#a3be8c;">CHROMA_TELEMETRY_ENABLED</span><span>&quot;] = &quot;</span><span style="color:#a3be8c;">false</span><span>&quot;
</span><span>os.environ[&quot;</span><span style="color:#a3be8c;">ANONYMIZED_TELEMETRY</span><span>&quot;] = &quot;</span><span style="color:#a3be8c;">false</span><span>&quot;
</span><span>
</span><span style="color:#65737e;"># same embedding model as ingest
</span><span style="color:#bf616a;">EMB_MODEL </span><span>= &quot;</span><span style="color:#a3be8c;">paraphrase-multilingual-MiniLM-L12-v2</span><span>&quot;
</span><span>emb = embedding_functions.</span><span style="color:#bf616a;">SentenceTransformerEmbeddingFunction</span><span>(</span><span style="color:#bf616a;">model_name</span><span>=</span><span style="color:#bf616a;">EMB_MODEL</span><span>)
</span><span>
</span><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">ask</span><span>(</span><span style="color:#bf616a;">query</span><span>: str, </span><span style="color:#bf616a;">k</span><span>: int = </span><span style="color:#d08770;">5</span><span>):
</span><span>    client = chromadb.</span><span style="color:#bf616a;">PersistentClient</span><span>(</span><span style="color:#bf616a;">path</span><span>=</span><span style="color:#bf616a;">DB_DIR</span><span>, </span><span style="color:#bf616a;">settings</span><span>=</span><span style="color:#bf616a;">Settings</span><span>(</span><span style="color:#bf616a;">anonymized_telemetry</span><span>=</span><span style="color:#d08770;">False</span><span>))
</span><span>    coll = client.</span><span style="color:#bf616a;">get_or_create_collection</span><span>(</span><span style="color:#bf616a;">name</span><span>=</span><span style="color:#bf616a;">COLLECTION</span><span>, </span><span style="color:#bf616a;">embedding_function</span><span>=emb)
</span><span>    res = coll.</span><span style="color:#bf616a;">query</span><span>(</span><span style="color:#bf616a;">query_texts</span><span>=[query], </span><span style="color:#bf616a;">n_results</span><span>=k)
</span><span>
</span><span>    docs = res.</span><span style="color:#bf616a;">get</span><span>(&quot;</span><span style="color:#a3be8c;">documents</span><span>&quot;, [[]])[</span><span style="color:#d08770;">0</span><span>]
</span><span>    metas = res.</span><span style="color:#bf616a;">get</span><span>(&quot;</span><span style="color:#a3be8c;">metadatas</span><span>&quot;, [[]])[</span><span style="color:#d08770;">0</span><span>]
</span><span>
</span><span>    </span><span style="color:#96b5b4;">print</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;</span><span style="color:#a3be8c;">üîé Query: </span><span>{query}</span><span style="color:#96b5b4;">\n</span><span>&quot;)
</span><span>    </span><span style="color:#b48ead;">for </span><span>i, (doc, meta) </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">enumerate</span><span>(</span><span style="color:#96b5b4;">zip</span><span>(docs, metas), </span><span style="color:#bf616a;">start</span><span>=</span><span style="color:#d08770;">1</span><span>):
</span><span>        </span><span style="color:#96b5b4;">print</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;</span><span style="color:#a3be8c;">[</span><span>{i}</span><span style="color:#a3be8c;">] </span><span>{meta.</span><span style="color:#bf616a;">get</span><span>(&#39;</span><span style="color:#a3be8c;">source</span><span>&#39;, &#39;</span><span style="color:#a3be8c;">?</span><span>&#39;)}&quot;)
</span><span>        </span><span style="color:#65737e;"># show first ~200 chars only
</span><span>        </span><span style="color:#96b5b4;">print</span><span>(doc[:</span><span style="color:#d08770;">200</span><span>].</span><span style="color:#bf616a;">replace</span><span>(&quot;</span><span style="color:#96b5b4;">\n</span><span>&quot;, &quot; &quot;) + &quot;</span><span style="color:#a3be8c;">...</span><span style="color:#96b5b4;">\n</span><span>&quot;)
</span><span>
</span><span style="color:#b48ead;">if </span><span>__name__ == &quot;</span><span style="color:#a3be8c;">__main__</span><span>&quot;:
</span><span>    </span><span style="color:#b48ead;">if </span><span style="color:#96b5b4;">len</span><span>(sys.argv) &lt; </span><span style="color:#d08770;">2</span><span>:
</span><span>        </span><span style="color:#96b5b4;">print</span><span>(&quot;</span><span style="color:#a3be8c;">Usage: python ask_minimal.py &#39;your question&#39;</span><span>&quot;)
</span><span>        sys.</span><span style="color:#bf616a;">exit</span><span>(</span><span style="color:#d08770;">1</span><span>)
</span><span>
</span><span>    </span><span style="color:#bf616a;">ask</span><span>(sys.argv[</span><span style="color:#d08770;">1</span><span>])
</span><span>
</span></code></pre>
<hr />
<h2 id="example-1-rehousing">Example 1: Rehousing</h2>
<p>A question might look like this:</p>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">python</span><span> ask_minimal.py &quot;</span><span style="color:#a3be8c;">Hvad siger ¬ß 85 om genhusning?</span><span>&quot;
</span></code></pre>
<p>And the answer:</p>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">[1]</span><span> kapitel-10/¬ß085/chunk-001.md
</span><span style="color:#bf616a;">Lejeren</span><span> har krav p√• en erstatningsbolig, hvis udlejeren opsiger lejem√•let p√• grund af st√∏rre ombygning...
</span><span>
</span><span style="color:#bf616a;">[2]</span><span> kapitel-10/¬ß086/chunk-001.md
</span><span style="color:#bf616a;">Kommunalbestyrelsen</span><span> kan i s√¶rlige tilf√¶lde...
</span><span>
</span></code></pre>
<hr />
<h2 id="example-2-a-failure-case">Example 2: A Failure Case</h2>
<p>Not every question works perfectly.</p>
<p><strong>Question:</strong></p>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">python</span><span> ask.py &quot;</span><span style="color:#a3be8c;">Can my landlord paint my living room pink without asking me?</span><span>&quot;
</span></code></pre>
<p><strong>Answer:</strong>
The model will probably say something <em>plausible</em> about maintenance rules or landlord obligations ‚Äî but it may not cite the exact relevant law.</p>
<p>This shows the limits: if your question doesn‚Äôt map cleanly to how the law is written, retrieval can miss the right chunk.</p>
<hr />
<h2 id="why-this-works">Why This Works</h2>
<p>This approach is called <strong>RAG (Retrieval-Augmented Generation)</strong>.</p>
<ul>
<li>Instead of asking the LLM to ‚Äúknow‚Äù Danish housing law (it doesn‚Äôt), we <strong>ground</strong> it in the actual text.</li>
<li>Chroma retrieves the most relevant paragraphs.</li>
<li>Ollama just rephrases those paragraphs into a human-friendly answer.</li>
</ul>
<p>The assistant isn‚Äôt a lawyer ‚Äî but it saves you from digging through 100 pages of legalese to find ¬ß86a.</p>
<hr />
<h2 id="reflections">Reflections</h2>
<ul>
<li><strong>Transparency</strong>: Every answer includes citations.</li>
<li><strong>Not magic</strong>: If the retrieval step fails, the answer can drift.</li>
<li><strong>Reusable pattern</strong>: You can replace the law with manuals, policies, or any other big text corpus.</li>
</ul>
<hr />
<h2 id="what-s-next">What‚Äôs Next?</h2>
<p>Right now, we have a working CLI assistant. Next steps could be:</p>
<ul>
<li>Wrapping this in a <strong>FastAPI</strong> or <strong>Flask</strong> web app.</li>
<li>Adding a search interface with highlighting.</li>
<li>Expanding with more laws ‚Üí building a small searchable <strong>legal AI library</strong>.</li>
</ul>
<hr />
<h2 id="final-thoughts">Final Thoughts</h2>
<p>Without using thousands of lines of Python, we built a system that:</p>
<ul>
<li>Splits and cleans a law text.</li>
<li>Stores it in a vector database.</li>
<li>Retrieves the right chunks for a question.</li>
<li>Uses an LLM to explain the result with citations.</li>
</ul>
<p>It‚Äôs not perfect and it's certainly not magic. But it can be <strong>useful</strong>.<br />
And in my book, that beats AI-hype slides about ‚Äúmachine learning for milk cartons‚Äù any day üç∫.</p>

</main>

    <div class="dark-mode-buttons">
        <button class="dark-mode-button" id="dark-mode-on"><img src="https://elvim.cc/dark_mode.svg" width="24" height="24" alt="Dark mode" aria-label="dark mode toggle" title="Dark mode"></button>
        <button class="dark-mode-button" id="dark-mode-off"><img src="https://elvim.cc/light_mode.svg" width="24" height="24" alt="Light mode" aria-label="light mode toggle" title="Light mode"></button>
    </div>
    <script>
        const cls = document.querySelector("html").classList;
        const sessionTheme = sessionStorage.getItem("theme");

        function setDark() {
            cls.add("dark-mode");
            cls.remove("light-mode");
            sessionStorage.setItem("theme", "dark");
        }
        function setLight() {
            cls.add("light-mode");
            cls.remove("dark-mode");
            sessionStorage.setItem("theme", "light");
        }

        if (sessionTheme === "dark") {
            setDark();
        } else if (sessionTheme === "light") {
            setLight();
        } else if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
            setDark();
        }

        document.getElementById("dark-mode-on").addEventListener("click", function(e) {
            setDark();
        });
        document.getElementById("dark-mode-off").addEventListener("click", function(e) {
            setLight();
        });
    </script>
    <noscript>
        <style>
            .dark-mode-buttons {
                display: none;
            }
        </style>
    </noscript>
</body>
</html>
